{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\t\t\t\t\t\t\n",
    "\tNAME\tDM [pc cm**-3]\tS/N (AMBER)\tRA\tDEC\tPOINTING NAME\tCB Found\n",
    "\t\t\t\t\t\t\t\n",
    "1\tFRB 190709\t663.4\t15.4\t01h36m06.7s\t+31d51m22.8s\t3C48drift2732\t10\n",
    "2\tFRB 190903\t663.8\t10.8\t01h32m43.2805s\t+33d04m48.9206s\t\t4\n",
    "3\tFRB 190925\t956.7\t12.9\t01h41m49.s\t+30d59m24.4s\t\t7\n",
    "4\tFRB 191020\t465\t13.2\t20h30m52 \t+61d58m47s\tT2029+6307\t5\n",
    "5\tFRB 191108\t587\t60\t01h33m57.35s\t+31d45m38s\tFRBfield\t21\n",
    "6\tFRB 191109\t531\t13\t20:33:51\t61:46:30\tFRB191020\t18\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python2 /home/arts/ARTS-obs/external/arts-analysis/triggers.py \n",
    "--rficlean\n",
    "--sig_thresh_local 5\n",
    "--time_limit 9000.0\n",
    "--descending_snr \n",
    "--beamno 00\n",
    "--dm_min 29.360000000000003\n",
    "--dm_max 5000\n",
    "--sig_thresh 10 \n",
    "--ndm 64\n",
    "--save_data concat\n",
    "--nfreq_plot 64\n",
    "--ntime_plot 64\n",
    "--cmap viridis \n",
    "--outdir=/data2/output/20191129/2019-11-29-09:45:00.T1703+6759/triggers \n",
    "--clean_type perchannel\n",
    "--synthesized_beams\n",
    "--sbmin 36\n",
    "--sbmax 70 \n",
    "--central_freq 1370 \n",
    "/data2/output/20191129/2019-11-29-09:45:00.T1703+6759/filterbank/CB00 \n",
    "/data2/output/20191129/2019-11-29-09:45:00.T1703+6759/amber/CB00.trigger\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "# from matplotlib import rc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import figaspect\n",
    "from matplotlib import rc\n",
    "import datetime\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from astropy.visualization import hist as ahist\n",
    "\n",
    "from . import *\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import scipy\n",
    "\n",
    "\n",
    "rc('font', size=12)\n",
    "rc('axes', titlesize=16)\n",
    "rc('axes', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abline(slope, intercept):\n",
    "    \"\"\"Plot a line from slope and intercept\"\"\"\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, '--')\n",
    "    \n",
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_singlepulse_dev(fn, max_rows=None, beam=None):\n",
    "    \"\"\" Read in text file containing single-pulse \n",
    "    candidates. Allowed formats are:\n",
    "    .singlepulse = PRESTO output\n",
    "    .txt = injection pipeline output\n",
    "    .trigger = AMBER output \n",
    "    .cand = heimdall output \n",
    "\n",
    "    max_rows sets the maximum number of \n",
    "    rows to read from textfile \n",
    "    beam is the beam number to pick in case of .trigger files\n",
    "    \"\"\"\n",
    "\n",
    "    if fn.split('.')[-1] in ('singlepulse', 'txt'):\n",
    "        A = np.genfromtxt(fn, max_rows=max_rows)\n",
    "\n",
    "        if len(A.shape) == 1:\n",
    "            A = A[None]\n",
    "\n",
    "        dm, sig, tt, downsample = A[:,0], A[:,1], A[:,2], A[:,4]\n",
    "    elif fn.split('.')[-1] == 'trigger':\n",
    "        A = np.genfromtxt(fn, max_rows=max_rows)\n",
    "\n",
    "        if len(A.shape) == 1:\n",
    "            A = A[None]\n",
    "\n",
    "        # Check if amber has compacted, in which case \n",
    "        # there are two extra rows\n",
    "        if len(A[0]) > 7:\n",
    "            if len(A[0])==8:\n",
    "                # beam batch sample integration_step compacted_integration_steps time DM compacted_DMs SNR\n",
    "                beamno, dm, sig, tt, downsample = A[:, 0], A[:, -3], A[:, -1], A[:, -4], A[:, 3]\n",
    "            elif len(A[0])==10:\n",
    "                beamno, dm, sig, tt, downsample = A[:, 0], A[:, -3], A[:, -1], A[:, -5], A[:, 3]\n",
    "            else:\n",
    "                print(\"Error: DO NOT RECOGNIZE COLUMNS OF .trigger FILE\")\n",
    "                return \n",
    "        else:\n",
    "            # beam batch sample integration_step time DM SNR\n",
    "            beamno, dm, sig, tt, downsample = A[:, 0], A[:,-2], A[:,-1], A[:, -3], A[:, 3]\n",
    "        \n",
    "        if beam is not None and beam != 'all':\n",
    "                # pick only the specified beam\n",
    "                dm = dm[beamno.astype(int) == beam]\n",
    "                sig = sig[beamno.astype(int) == beam]\n",
    "                tt = tt[beamno.astype(int) == beam]\n",
    "                downsample = downsample[beamno.astype(int) == beam]\n",
    "\n",
    "    elif fn.split('.')[-1] == 'cand':\n",
    "        A = np.genfromtxt(fn, max_rows=max_rows)\n",
    "\n",
    "        if len(A.shape) == 1:\n",
    "            A = A[None]\n",
    "        \n",
    "        # SNR sample_no time log_2_width DM_trial DM Members first_samp last_samp\n",
    "        dm, sig, tt, log_2_downsample = A[:,5], A[:,0], A[:, 2], A[:, 3]\n",
    "        downsample = 2**log_2_downsample\n",
    "        try:\n",
    "            beamno = A[:, 9]\n",
    "            return dm, sig, tt, downsample, beamno\n",
    "        except:\n",
    "            pass\n",
    "    elif fn.split('.')[-1]=='fredda':\n",
    "        A = np.genfromtxt(fn, max_rows=max_rows)\n",
    "\n",
    "        if len(A.shape)==1:\n",
    "            A = A[None]\n",
    "        \n",
    "        dm, sig, tt, downsample = A[:,5], A[:,0], A[:, 2], A[:, 3]\n",
    "    else:\n",
    "        print(\"Didn't recognize singlepulse file\")\n",
    "        return \n",
    "\n",
    "    if len(A) == 0:\n",
    "        if beam == 'all':\n",
    "            return 0, 0, 0, 0, 0\n",
    "        else:\n",
    "            return 0, 0, 0, 0\n",
    "\n",
    "    if beam == 'all':\n",
    "        return dm, sig, tt, downsample, beamno\n",
    "    else:\n",
    "        return dm, sig, tt, downsample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triggers_dev(fn, sig_thresh=5.0, dm_min=0, dm_max=np.inf, \n",
    "                 t_window=0.5, max_rows=None, t_max=np.inf,\n",
    "                 sig_max=np.inf, dt=2*40.96, delta_nu_MHz=300./1536, \n",
    "                 nu_GHz=1.4, fnout=False, tab=None, read_beam=False, dm_width_filter=False):\n",
    "    \"\"\" Get brightest trigger in each 10s chunk.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fn : str \n",
    "        filename with triggers (.npy, .singlepulse, .trigger)\n",
    "    sig_thresh : float\n",
    "        min S/N to include\n",
    "    dm_min : \n",
    "        minimum dispersion measure to allow \n",
    "    dm_max : \n",
    "        maximum dispersion measure to allow \n",
    "    t_window : float \n",
    "        Size of each time window in seconds\n",
    "    max_rows : \n",
    "        Only read this many rows from raw trigger file \n",
    "    fnout : str \n",
    "        name of text file to save clustered triggers to \n",
    "    tab : int\n",
    "        which TAB to process (0 for IAB)\n",
    "    read_beam: bool\n",
    "        read and return beam number (default: False)\n",
    "        all beams are read if this is true\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sig_cut : ndarray\n",
    "        S/N array of brightest trigger in each DM/T window \n",
    "    dm_cut : ndarray\n",
    "        DMs of brightest trigger in each DM/T window \n",
    "    tt_cut : ndarray\n",
    "        Arrival times of brightest trigger in each DM/T window \n",
    "    ds_cut : ndarray \n",
    "        downsample factor array of brightest trigger in each DM/T window\n",
    "    beam_cut: ndarray\n",
    "        beam array of brightest trigger in each DM/T windows (only if read_beam is True)\n",
    "    \"\"\"\n",
    "    if tab is not None:\n",
    "        beam_amber = tab\n",
    "    elif read_beam:\n",
    "        beam_amber = 'all'\n",
    "    else:\n",
    "        beam_amber = None\n",
    "\n",
    "    if type(fn) == str:\n",
    "        if read_beam:\n",
    "            dm, sig, tt, downsample, beam = read_singlepulse_dev(fn, max_rows=max_rows, beam=beam_amber)[:5]\n",
    "        else:\n",
    "            dm, sig, tt, downsample = read_singlepulse_dev(fn, max_rows=max_rows, beam=beam_amber)[:4]\n",
    "    elif type(fn) == np.ndarray:\n",
    "        dm, sig, tt, downsample = fn[:, 0], fn[:, 1], fn[:, 2], fn[:, 3]\n",
    "    else:\n",
    "        print(\"Wrong input type. Expected string or ndarray\")\n",
    "        if read_beam:\n",
    "            return [], [], [], [], [], []\n",
    "        else:\n",
    "            return [], [], [], [], []\n",
    "\n",
    "    ntrig_orig = len(dm)\n",
    "\n",
    "    bad_sig_ind = np.where((sig < sig_thresh) | (sig > sig_max))[0]\n",
    "    sig = np.delete(sig, bad_sig_ind)\n",
    "    tt = np.delete(tt, bad_sig_ind)\n",
    "    dm = np.delete(dm, bad_sig_ind)\n",
    "    downsample = np.delete(downsample, bad_sig_ind)\n",
    "    sig_cut, dm_cut, tt_cut, ds_cut = [], [], [], []\n",
    "    if read_beam:\n",
    "        beam = np.delete(beam, bad_sig_ind)\n",
    "        beam_cut = []\n",
    "\n",
    "    if len(tt) == 0:\n",
    "        print(\"Returning None: time array is empty\")\n",
    "        return \n",
    "\n",
    "    tduration = tt.max() - tt.min()\n",
    "    ntime = int(tduration / t_window)\n",
    "\n",
    "    # Make dm windows between 90% of the lowest trigger and \n",
    "    # 10% of the largest trigger\n",
    "    if dm_min == 0:\n",
    "        dm_min = 0.9*dm.min()\n",
    "    if dm_max > 1.1*dm.max():\n",
    "        dm_max = 1.1*dm.max()\n",
    "\n",
    "    # Can either do the DM selection here, or after the loop\n",
    "#    dm_list = dm_range(dm_max, dm_min=dm_min)\n",
    "    dm_list = dm_range(1.1*dm.max(), dm_min=0.9*dm.min())\n",
    "\n",
    "    print(\"\\nGrouping in window of %.2f sec\" % np.round(t_window,2))\n",
    "    print(\"DMs:\", dm_list)\n",
    "\n",
    "    tt_start = tt.min() - .5*t_window\n",
    "    ind_full = []\n",
    "\n",
    "    # might wanna make this a search in (dm,t,width) cubes\n",
    "    for dms in dm_list:\n",
    "        for ii in range(ntime + 2):\n",
    "            try:    \n",
    "                # step through windows of t_window seconds, starting from tt.min()\n",
    "                # and find max S/N trigger in each DM/time box\n",
    "                t0, tm = t_window*ii + tt_start, t_window*(ii+1) + tt_start\n",
    "                ind = np.where((dm<dms[1]) & (dm>dms[0]) & (tt<tm) & (tt>t0))[0] \n",
    "                \n",
    "                if len(ind) > 0:\n",
    "                    plt.plot(sig[ind], label=ii)\n",
    "                \n",
    "                ind_maxsnr = ind[np.argmax(sig[ind])]\n",
    "                sig_cut.append(sig[ind_maxsnr])\n",
    "                dm_cut.append(dm[ind_maxsnr])\n",
    "                tt_cut.append(tt[ind_maxsnr])\n",
    "                ds_cut.append(downsample[ind_maxsnr])\n",
    "                if read_beam:\n",
    "                    beam_cut.append(beam[ind_maxsnr])\n",
    "                ind_full.append(ind_maxsnr)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    ind_full = np.array(ind_full)\n",
    "    dm_cut = np.array(dm_cut)\n",
    "    # now remove the low DM candidates\n",
    "    tt_cut = np.array(tt_cut).astype(np.float)\n",
    "    ind = np.where((dm_cut >= dm_min) & (dm_cut <= dm_max) & (tt_cut < t_max))[0]\n",
    "\n",
    "    dm_cut = dm_cut[ind]\n",
    "    ind_full = ind_full[ind]\n",
    "    sig_cut = np.array(sig_cut)[ind]\n",
    "    tt_cut = tt_cut[ind]\n",
    "    ds_cut = np.array(ds_cut)[ind]\n",
    "    if read_beam:\n",
    "        beam_cut = np.array(beam_cut)[ind]\n",
    "\n",
    "    ntrig_group = len(dm_cut)\n",
    "\n",
    "    print(\"Grouped down to %d triggers from %d\\n\" % (ntrig_group, ntrig_orig))\n",
    "\n",
    "    rm_ii = []\n",
    "\n",
    "    if dm_width_filter:\n",
    "        for ii in range(len(ds_cut)):        \n",
    "            tdm = 8.3 * delta_nu_MHz / nu_GHz**3 * dm_cut[ii] # microseconds#\n",
    "\n",
    "            if ds_cut[ii]*dt < (0.5*(dt**2 + tdm**2)**0.5):\n",
    "                rm_ii.append(ii)\n",
    "\n",
    "    dm_cut = np.delete(dm_cut, rm_ii)\n",
    "    tt_cut = np.delete(tt_cut, rm_ii)\n",
    "    sig_cut = np.delete(sig_cut, rm_ii)\n",
    "    ds_cut = np.delete(ds_cut, rm_ii)\n",
    "    if read_beam:\n",
    "        beam_cut = np.delete(beam_cut, rm_ii)\n",
    "    ind_full = np.delete(ind_full, rm_ii)\n",
    "\n",
    "    if fnout:\n",
    "        if read_beam:\n",
    "            clustered_arr = np.concatenate([sig_cut, dm_cut, tt_cut, ds_cut, beam_cut, ind_full])\n",
    "            clustered_arr = clustered_arr.reshape(6, -1)\n",
    "        else:\n",
    "            clustered_arr = np.concatenate([sig_cut, dm_cut, tt_cut, ds_cut, ind_full])\n",
    "            clustered_arr = clustered_arr.reshape(5, -1)\n",
    "        np.savetxt(fnout, clustered_arr) \n",
    "\n",
    "    if read_beam:\n",
    "        return sig_cut, dm_cut, tt_cut, ds_cut, beam_cut, ind_full\n",
    "    else:\n",
    "        return sig_cut, dm_cut, tt_cut, ds_cut, ind_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load / parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iiii=30\n",
    "\n",
    "plt.plot(beams[iiii], (sigs[iiii]-np.max(sigs[iiii]))/np.median(sigs[iiii]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(beams[30], dms_[30])\n",
    "abline(0, np.median(dms_[30]))\n",
    "print (np.median(dms_[30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iiii = 70\n",
    "iiii = 40\n",
    "\n",
    "# __s = 1+(sigs[iiii]-np.max(sigs[iiii]))/(np.max(sigs[iiii])-np.min(sigs[iiii]))\n",
    "__s = (sigs[iiii]-np.median(sigs[iiii]))/(np.std(sigs[iiii]))\n",
    "\n",
    "plt.plot(beams[iiii], __s)\n",
    "abline(0, np.max(__s) - np.std(__s))\n",
    "\n",
    "np.count_nonzero(\n",
    "    np.isclose(\n",
    "        [__s], \n",
    "        [np.max(__s)], \n",
    "        atol=np.std(__s)\n",
    "    )\n",
    ")\n",
    "\n",
    "for beam, sb in zip(beams[iiii], sigs[iiii]):\n",
    "    print (beam, sb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(beams[iiii], dms_[iiii])\n",
    "abline(0, np.median(dms_[iiii]))\n",
    "print (np.median(dms_[iiii]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = []\n",
    "peaks = []\n",
    "\n",
    "# Find FRB 191108:\n",
    "for i, snr in enumerate(sigs):\n",
    "    snr = np.asarray(snr)\n",
    "    ranges.append(snr.max()-snr.min())\n",
    "#     _s = 1+(snr-np.max(snr))/(np.max(snr)-np.min(snr))\n",
    "    _s = (snr-np.median(snr))/(np.std(snr))\n",
    "    peaks.append(\n",
    "        np.count_nonzero(\n",
    "            np.isclose(\n",
    "                [_s], \n",
    "                [np.max(_s)], \n",
    "                atol=np.std(_s)\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ranges)\n",
    "plt.xlabel('Trigger X')\n",
    "plt.ylabel('SNR range (max-min)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(peaks))\n",
    "plt.hist(peaks, bins=np.asarray(range(len(peaks)+1)))\n",
    "# plt.xlabel('Trigger X')\n",
    "# plt.ylabel('N peaks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in  enumerate(ranges):\n",
    "    print (\"%d\\t%.5f\" % (i, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(([(sigs[iiii]-np.max(sigs[iiii]))/np.median(sigs[iiii])]), [0], atol=0.1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(\n",
    "    np.isclose(\n",
    "        [_s], \n",
    "        [1], \n",
    "        atol=0.05\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(beams[iiii], sigs[iiii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npoints = 5\n",
    "\n",
    "print (sigs[iiii][np.argsort(sigs[iiii])[-npoints:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(sigs[iiii])[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iiii = 40\n",
    "ntop = 10\n",
    "\n",
    "_sorted = np.argsort(sigs[iiii])[-ntop:]\n",
    "\n",
    "top_sigs = np.asarray(sigs[iiii])[_sorted]\n",
    "top_beams = np.asarray(beams[iiii])[_sorted]\n",
    "\n",
    "slope, intercept, rvalue, pvalue, stderr = stats.linregress(top_beams, top_sigs)\n",
    "\n",
    "print(\"slope\", slope, )\n",
    "print(\"intercept\", intercept, )\n",
    "print(\"rvalue\", rvalue, )\n",
    "print(\"pvalue\", pvalue, )\n",
    "print(\"stderr\", stderr)\n",
    "\n",
    "plt.plot(beams[iiii], sigs[iiii])\n",
    "abline(slope, intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iiii = 22\n",
    "\n",
    "_sorted = np.argsort(sigs[iiii])[-ntop:]\n",
    "top_sigs = np.asarray(sigs[iiii])[_sorted]\n",
    "top_beams = np.asarray(beams[iiii])[_sorted]\n",
    "\n",
    "slope, intercept, rvalue, pvalue, stderr = stats.linregress(top_beams, top_sigs)\n",
    " \n",
    "print(\"slope\", slope, )\n",
    "print(\"intercept\", intercept, )\n",
    "print(\"rvalue\", rvalue, )\n",
    "print(\"pvalue\", pvalue, )\n",
    "print(\"stderr\", stderr)\n",
    "\n",
    "plt.scatter(beams[iiii], sigs[iiii])\n",
    "abline(slope, intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sigs[40], len(sigs[40])//2)\n",
    "plt.xlabel('SNR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sigs[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sigs[20], len(sigs[20])//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sigs[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sigs[127])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sigs[127])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigs[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.absolute(np.fft.fft(sigs[40])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.(sigs[17]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sigs[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(beams[40], sigs[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.NAN(71)\n",
    "arr[np.array(beams[40]).astype(int)] = sigs[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.absolute(np.fft.fft(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 71, 11):\n",
    "    print (i, np.absolute(np.fft.fft(arr))[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "idx = 40\n",
    "# idx = 101 \n",
    "\n",
    "print (beams[idx])\n",
    "print (sigs[idx])\n",
    "\n",
    "a = np.empty(71)\n",
    "a[:] = 8\n",
    "a[np.array(beams[idx]).astype(int)] = sigs[idx]\n",
    "nans, x= nan_helper(a)\n",
    "a[nans]= np.interp(x(nans), x(~nans), a[~nans])\n",
    "# if 11 in scipy.signal.find_peaks(np.absolute(np.fft.fft(a))):\n",
    "#     print ('Yay')\n",
    "fig, ax = plt.subplots(2,1)\n",
    "\n",
    "ax[0].plot(a)\n",
    "ax[0].set_xlabel('SB')\n",
    "ax[0].set_ylabel('SNR')\n",
    "ax[1].plot(np.absolute(np.fft.fft(a)[1:]))\n",
    "ax[1].set_xlabel('Freq')\n",
    "ax[1].set_ylabel('Amplitude')\n",
    "plt.tight_layout()\n",
    "\n",
    "fourier_dom = np.absolute(np.fft.fft(a))\n",
    "\n",
    "fourier_dom.shape\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(0, 71, 11):\n",
    "#     print (i, np.absolute(np.fft.fft(a))[i])\n",
    "    \n",
    "# print ()\n",
    "\n",
    "# for i, j in enumerate(np.absolute(np.fft.fft(a))):\n",
    "#     print (i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier_dom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier_dom[11]/fourier_dom[30:40].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_idx = 2\n",
    "a = np.empty(71)\n",
    "a[:] = np.nan\n",
    "a[np.array(beams[_idx]).astype(int)] = sigs[_idx]\n",
    "nans, x= nan_helper(a)\n",
    "a[nans]= np.interp(x(nans), x(~nans), a[~nans])\n",
    "plt.plot(np.absolute(np.fft.fft(a)))\n",
    "\n",
    "fourier_dom = np.absolute(np.fft.fft(a))\n",
    "\n",
    "# for i in range(0, 71, 11):\n",
    "#     print (i, np.absolute(np.fft.fft(a))[i])\n",
    "    \n",
    "# print ()\n",
    "\n",
    "# for i, j in enumerate(np.absolute(np.fft.fft(a))):\n",
    "#     print (i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
